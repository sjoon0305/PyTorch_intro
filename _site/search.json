[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/PT1.html",
    "href": "posts/PT1.html",
    "title": "파이토치 딥러닝 마스터 1장",
    "section": "",
    "text": "기존의 머신러닝 vs 딥러닝(패러다임의 전환)\n\n\n기존의 머신러닝을 이용한 시스템은 피처 엔지니어링(feature engineering)에 크게 의존\n이는 새로운 데이터를 기반으로 올바른 결과물을 낼 수 있도록 데이터 전처리 과정이 필요\n반면 딥러닝의 경우 데이터 전처리(변환) 과정 없이 원본 데이터로 부터 답을 도출\n딥러닝 실무에서는 표현을 수작업으로 만드는 것(머신러닝) 보다 수학적 개체(신경망 모델)를 조작해 훈련 데이터 로 부터 표현을 자동으로 훈련시키는 데에 집중\n훈련을 시킬 때에는 기준을 통해 점점 더 낮은 점수(손실이 낮아지도록) 점진적으로 딥러닝 머신을 변경\n\n\n- 딥러닝을 성공적으로 실행하기 위해 필요한 요구사항\n\n가지고 있는 데이터가 무엇이든 일단 넣을 수 있어야한다.\n딥러닝 머신을 정의해야한다.\n유용한 표현을 얻고 머신이 원하는 출력 결과를 낼 수 있도록 자동화된 훈련 방법을 만들어야한다.\n\n\n\n\n- 파이토치란?\n\n딥러닝 프로젝트를 위한 파이썬 프로그램 라이브러리\n파이토치는 현재 고수준의 작업을 위한 전문적인 도구로도 전혀 손색이 없음\n파이토치에서는 텐서(tensor) 라는 핵심 데이터 구조를 제공하여 전용 하드웨어를 활용하여 수학 연산을 빠르게수행\n파이토치는 신경망 아키텍처를 설계하고 개별 혹은 분산 컴퓨팅 자원에서 훈련하기 매우 편리하다는 장.\n\n\n텐서(tensor) 란? - 넘파이(NumPy) 배열과 여러면에서 유사한 다차원 배열. 차후 뒤에서 배운다.\n\n\n\n\n\n딥러닝을 학습시키기 위해서는 다양한 문제에 적용할 수 있을 정도로 유연하면서도, 적당한 시간 안에 많은 양의 데이터로 훈련 가능한 효율적인 도구가 필요\n\n\n단순함\n\n\n파이토치는 학습이나 활용, 확장, 디버깅 면에서 모두 수월하다고한다. 파이토치는 파이썬스러운 면이 강하다. (텐서가 넘파이 구조체와 비슷하기 때문에, 파이썬처럼 interactive 하게 사용 가능하다. )\n\n\n정교한 딥러닝에 최적화\n\n\n파이토치는 딥러닝을 위해 그래픽 연산 유닛인 GPU 로 연산을 가속할 수 있다. 이는 CPU 에서 처리하는 것보다 50배나 빠른 결과를 보여준다. 또한 훈련을 위해 딥러닝이 사용하는 일반 수학식에 대해 산술 최적화를 지원한다.\n\n\n다른 모델, 언어와 인터렉트가 가능\n\n\n파이썬에 의존하지 않고 추론 가능한 모델을 배포하기 위해 C++ 런타임을 갖추면서 다른 언어를 지원하는 바인딩과 모바일 장비에 배포하기 위한 인터페이스를 늘리고 있다. 파이토치의 유연함을 잘 보여준다.\n\n\n\n\n\n파이토치는 기본적으로 다차원 배열 혹은 파이토치 언어로는 텐서라 부르는 자료구조를 사용하는 라이브러리이다. 따라서 텐서를 사용하는 다양한 연산 라이브러리를 torch 모듈 로 제공한다.\n텐서 자료구조나 이를 사용한 연산은 CPU 나 GPU 함수 호출로 가능하다. 특정 텐서에 수행한 모든 연산을 기억해뒀다가 주어진 입력값을 기준으로 미분값을 자동 계산해준다. 파이토치의 계산 최적화 기능 은 내부적으로 파이토치의 자동미분 엔진이 텐서를 사용하기 때문에 가능하다.\n신경망 구축을 지원하는 파이토치 핵심 모듈은 torch.nn 에 있으며 공통적인 신경망과 아키텍처적인 구성 요소를 제공한다. (여기에 완전 연결 계층이나 컨볼루션층, 활성화 함수, 손실 함수가 모두 포함된다.)\n추가적으로 모델 훈련을 위해 모델을 훈련 데이터에 맞춰주는 옵티마이저(optimizer) 와 모델과 데이터로 모델 훈련을 위해 필요한 계산을 수행할 하드웨어 등이 필요하다.\n가져온 데이터의 각각 샘플을 파이토치가 다룰 수 있는 텐서로 변환을 해야하는데, 이 때 torch.utils.data 에 있는 Dataset 클래스 가 필요하며 다양한 타입의 데이터를 원하는 형태의 텐서로 표현가능하다.\n이렇게 변환된 텐서를 여러 개의 훈련 샘플을 묶어놓은 텐서 형태인 배치(batch) 로 데이터를 묶기 위해 병렬 처리가 필요하게된다. 이때 DataLoader 클래스 를 사용한다.\n자, 이제 훈련을 진행하면, 훈련 루프는 매번 데이터 로더에서 얻은 샘플로 모델을 평가한다. 모델의 출력을 기대값과 비교하는 이때 criterion 혹은 손실 함수(loss function) 를 사용한다. 손실 함수 역시 torch.nn 에 있다.\n손실 함수로 출력 결과를 이상적인 결과와 비교한 후 다음 출력이 목표 출력을 더 잘 모사하게끔 모델을 조정하는데, 여기서 파이토치 자동 미분 엔진 을 사용한다."
  },
  {
    "objectID": "posts/PT1.html#딥러닝-혁명",
    "href": "posts/PT1.html#딥러닝-혁명",
    "title": "파이토치 딥러닝 마스터 1장",
    "section": "",
    "text": "기존의 머신러닝 vs 딥러닝(패러다임의 전환)\n\n\n기존의 머신러닝을 이용한 시스템은 피처 엔지니어링(feature engineering)에 크게 의존\n이는 새로운 데이터를 기반으로 올바른 결과물을 낼 수 있도록 데이터 전처리 과정이 필요\n반면 딥러닝의 경우 데이터 전처리(변환) 과정 없이 원본 데이터로 부터 답을 도출\n딥러닝 실무에서는 표현을 수작업으로 만드는 것(머신러닝) 보다 수학적 개체(신경망 모델)를 조작해 훈련 데이터 로 부터 표현을 자동으로 훈련시키는 데에 집중\n훈련을 시킬 때에는 기준을 통해 점점 더 낮은 점수(손실이 낮아지도록) 점진적으로 딥러닝 머신을 변경\n\n\n- 딥러닝을 성공적으로 실행하기 위해 필요한 요구사항\n\n가지고 있는 데이터가 무엇이든 일단 넣을 수 있어야한다.\n딥러닝 머신을 정의해야한다.\n유용한 표현을 얻고 머신이 원하는 출력 결과를 낼 수 있도록 자동화된 훈련 방법을 만들어야한다."
  },
  {
    "objectID": "posts/PT1.html#딥러닝을-위한-파이토치",
    "href": "posts/PT1.html#딥러닝을-위한-파이토치",
    "title": "파이토치 딥러닝 마스터 1장",
    "section": "",
    "text": "- 파이토치란?\n\n딥러닝 프로젝트를 위한 파이썬 프로그램 라이브러리\n파이토치는 현재 고수준의 작업을 위한 전문적인 도구로도 전혀 손색이 없음\n파이토치에서는 텐서(tensor) 라는 핵심 데이터 구조를 제공하여 전용 하드웨어를 활용하여 수학 연산을 빠르게수행\n파이토치는 신경망 아키텍처를 설계하고 개별 혹은 분산 컴퓨팅 자원에서 훈련하기 매우 편리하다는 장.\n\n\n텐서(tensor) 란? - 넘파이(NumPy) 배열과 여러면에서 유사한 다차원 배열. 차후 뒤에서 배운다."
  },
  {
    "objectID": "posts/PT1.html#파이토치를-쓰는-이유",
    "href": "posts/PT1.html#파이토치를-쓰는-이유",
    "title": "파이토치 딥러닝 마스터 1장",
    "section": "",
    "text": "딥러닝을 학습시키기 위해서는 다양한 문제에 적용할 수 있을 정도로 유연하면서도, 적당한 시간 안에 많은 양의 데이터로 훈련 가능한 효율적인 도구가 필요\n\n\n단순함\n\n\n파이토치는 학습이나 활용, 확장, 디버깅 면에서 모두 수월하다고한다. 파이토치는 파이썬스러운 면이 강하다. (텐서가 넘파이 구조체와 비슷하기 때문에, 파이썬처럼 interactive 하게 사용 가능하다. )\n\n\n정교한 딥러닝에 최적화\n\n\n파이토치는 딥러닝을 위해 그래픽 연산 유닛인 GPU 로 연산을 가속할 수 있다. 이는 CPU 에서 처리하는 것보다 50배나 빠른 결과를 보여준다. 또한 훈련을 위해 딥러닝이 사용하는 일반 수학식에 대해 산술 최적화를 지원한다.\n\n\n다른 모델, 언어와 인터렉트가 가능\n\n\n파이썬에 의존하지 않고 추론 가능한 모델을 배포하기 위해 C++ 런타임을 갖추면서 다른 언어를 지원하는 바인딩과 모바일 장비에 배포하기 위한 인터페이스를 늘리고 있다. 파이토치의 유연함을 잘 보여준다."
  },
  {
    "objectID": "posts/PT1.html#파이토치-큰-흐름",
    "href": "posts/PT1.html#파이토치-큰-흐름",
    "title": "파이토치 딥러닝 마스터 1장",
    "section": "",
    "text": "파이토치는 기본적으로 다차원 배열 혹은 파이토치 언어로는 텐서라 부르는 자료구조를 사용하는 라이브러리이다. 따라서 텐서를 사용하는 다양한 연산 라이브러리를 torch 모듈 로 제공한다.\n텐서 자료구조나 이를 사용한 연산은 CPU 나 GPU 함수 호출로 가능하다. 특정 텐서에 수행한 모든 연산을 기억해뒀다가 주어진 입력값을 기준으로 미분값을 자동 계산해준다. 파이토치의 계산 최적화 기능 은 내부적으로 파이토치의 자동미분 엔진이 텐서를 사용하기 때문에 가능하다.\n신경망 구축을 지원하는 파이토치 핵심 모듈은 torch.nn 에 있으며 공통적인 신경망과 아키텍처적인 구성 요소를 제공한다. (여기에 완전 연결 계층이나 컨볼루션층, 활성화 함수, 손실 함수가 모두 포함된다.)\n추가적으로 모델 훈련을 위해 모델을 훈련 데이터에 맞춰주는 옵티마이저(optimizer) 와 모델과 데이터로 모델 훈련을 위해 필요한 계산을 수행할 하드웨어 등이 필요하다.\n가져온 데이터의 각각 샘플을 파이토치가 다룰 수 있는 텐서로 변환을 해야하는데, 이 때 torch.utils.data 에 있는 Dataset 클래스 가 필요하며 다양한 타입의 데이터를 원하는 형태의 텐서로 표현가능하다.\n이렇게 변환된 텐서를 여러 개의 훈련 샘플을 묶어놓은 텐서 형태인 배치(batch) 로 데이터를 묶기 위해 병렬 처리가 필요하게된다. 이때 DataLoader 클래스 를 사용한다.\n자, 이제 훈련을 진행하면, 훈련 루프는 매번 데이터 로더에서 얻은 샘플로 모델을 평가한다. 모델의 출력을 기대값과 비교하는 이때 criterion 혹은 손실 함수(loss function) 를 사용한다. 손실 함수 역시 torch.nn 에 있다.\n손실 함수로 출력 결과를 이상적인 결과와 비교한 후 다음 출력이 목표 출력을 더 잘 모사하게끔 모델을 조정하는데, 여기서 파이토치 자동 미분 엔진 을 사용한다."
  },
  {
    "objectID": "posts/PT2.html",
    "href": "posts/PT2.html",
    "title": "파이토치 딥러닝 마스터 2장",
    "section": "",
    "text": "사전 훈련된 이미지 인식 모델 돌려보기\nGAN 과 사이클 GAN 을 소개\n이미지에서 텍스트 설명을 만들어낼 수 있는 자막 모델과 토치 허브에 모델 공유를 알아본다\n\n\n사전 훈련된 인기있는 모델 3가지\n\n\n이미지를 이해하고 레이블을 달아주는 모델\n진짜 이미지로부터 새로운 이미지를 만들어내는 모델\n이미지의 내용을 문법에 맞게 영어 문장으로 설명하는 모델"
  },
  {
    "objectID": "posts/PT3.html",
    "href": "posts/PT3.html",
    "title": "파이토치 딥러닝 마스터 3장",
    "section": "",
    "text": "파이토치 기본 자료구조인 텐서를 이해한다.\n텐서를 인덱스로 접근해서 연산한다\n다차원 배열 넘파이와 연계해서 다\n기 성능 개선을 위해 GPU로 연산 처리하기\n\n\n딥러닝 프로세스는 입력을 부동소수점 수로 변환하는 것부터 시작한다. 3장에서는 응용을 들어가기 전에 텐서 를 사용하여 파이토치가 부동소수점 수를 어떻게 다루는지를 알아보자\n\n- 부동 소수점 방식이란?\n실수는 보통 정수부와 소수부로 나누지만, 가수부와 지수부로 나누어 표현할 수 있다. 부동 소수점 방식은 이렇게 하나의 실수를 가수부와 지수부로 나누어 표현하는 방식이다. 앞서 살펴본 고정 소수점 방식은 제한된 자릿수로 인해 표현할 수 있는 범위가 매우 작다. 하지만 부동 소수점 방식은 다음 수식을 이용하여 매우 큰 실수까지도 표현할 수 있게 된다.\n\n\n\n심층 신경망(deep neural network)은 보통 여러 단계를 거쳐 데이터 변환을 학습한다.\n중간 단계는 입력값의 특징을 잡아내는 부동소수점 수의 모음인 동시에 신경망에서 입력이 최종적으로 출력으로 표현되는 방법을 기술하기 위한 수단이다.\n즉, 중간 표현값은 입력과 이전 층의 뉴런이 가진 가중치를 조합한 결과라는 점이다. 중간 단계의 개별 표현은 자신만의 방식으로 앞 단계에서 넘어온 입력을 반환한다.\n\n\n\n\n\n텐서는 일종의 배열이다. 즉, 한개나 여러개의 인덱스를 사용하여 개별적으로 값에 접근할 수 있는 형태의 숫자 모음을 저장하는 자료구조이다.\n\n- 텐서의 핵심 - 텐서는 자료구조를 사용해 이미지와 시계열 데이터 혹은 문장들을 나타내는 것이 일반 파이썬 리스트보다 더 효율적이다.\n\nimport torch\n\n\nt = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\nprint(t) #  1차원 텐서인 벡터를 만든다.\n\nprint(t.dim())  # rank. 즉, 차원\nprint(t.shape)  # shape\nprint(t.size()) # shape\n\ntensor([0., 1., 2., 3., 4., 5., 6.])\n1\ntorch.Size([7])\ntorch.Size([7])\n\n\n\n고급 인덱싱이 가능\n\n\nprint(t[0], t[1], t[-1])  # 인덱스로 접근\nprint(t[2:5], t[4:-1])    # 슬라이싱\nprint(t[:2], t[3:])       # 슬라이싱\n\ntensor(0.) tensor(1.) tensor(6.)\ntensor([2., 3., 4.]) tensor([4., 5.])\ntensor([0., 1.]) tensor([3., 4., 5., 6.])\n\n\n\n\n\n\n텐서끼리의 연산 대부분은 torch모듈 에 존재하며 대부분이 텐서 객체에 대해 메소드처럼 호출할 수 있다.\n\n\n\n\n\n텐서의 내부 값은 실제로는 torch.Storage인스턴스 로 관리하며 연속적인 메모리 조각으로 할당된 상태이다.\n저장 공간은 숫자 데이터를 가진 1차원 배열이다.\n\n- 여기서 중요한 점은 서로 다른 방식으로 구성된 텐서가 동일한 메모리 공간을 가리키고 있을 수 있으나, 동일한 데이터에 대해 다른 텐서 뷰를 만드는 작업은 Storage 객체가 관리하는 데이터 크기에 상관없이 빠르게 수행된다는 점이다.\n\n텐서의 저장공간 접근 확인을 위한 간단한 코드\n\n\n#텐서 저장 공간 접근\npoints = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints.storage()\n\n 4.0\n 1.0\n 5.0\n 3.0\n 2.0\n 1.0\n[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n\n\n\n#텐서를 거치지 않고 저장 공간을 직접 접근하는 방법 \n\npoints_storage = points.storage()\npoints_storage[0]\n\n4.0\n\n\n\n\n\n\n저장 공간을 인덱스로 접근하기 위해 텐서는 저장 공간에 포함된 몇 가지 명확한 정보, 즉 사이즈(size), 오프셋(offset), 스트라이드(stride) 에 의존한다.\n\n\n사이즈(size) : 텐서의 각 차원 별로 들어가는 요소의 수를 표시한 튜플\n오프셋(offset) : 텐서의 첫 번째 요소를 가리키는 색인 값과 동일\n스트라이드(stride) : 각 차원에서 다음 요소를 가리키고 싶을 때 실제 저장 공간상에서 몇 개의 요소를 건너뛰어야하는지를 알려주는 요소"
  },
  {
    "objectID": "posts/PT3.html#부동소수점",
    "href": "posts/PT3.html#부동소수점",
    "title": "파이토치 딥러닝 마스터 3장",
    "section": "",
    "text": "심층 신경망(deep neural network)은 보통 여러 단계를 거쳐 데이터 변환을 학습한다.\n중간 단계는 입력값의 특징을 잡아내는 부동소수점 수의 모음인 동시에 신경망에서 입력이 최종적으로 출력으로 표현되는 방법을 기술하기 위한 수단이다.\n즉, 중간 표현값은 입력과 이전 층의 뉴런이 가진 가중치를 조합한 결과라는 점이다. 중간 단계의 개별 표현은 자신만의 방식으로 앞 단계에서 넘어온 입력을 반환한다."
  },
  {
    "objectID": "posts/PT3.html#텐서-다차원-배열",
    "href": "posts/PT3.html#텐서-다차원-배열",
    "title": "파이토치 딥러닝 마스터 3장",
    "section": "",
    "text": "텐서는 일종의 배열이다. 즉, 한개나 여러개의 인덱스를 사용하여 개별적으로 값에 접근할 수 있는 형태의 숫자 모음을 저장하는 자료구조이다.\n\n- 텐서의 핵심 - 텐서는 자료구조를 사용해 이미지와 시계열 데이터 혹은 문장들을 나타내는 것이 일반 파이썬 리스트보다 더 효율적이다.\n\nimport torch\n\n\nt = torch.FloatTensor([0., 1., 2., 3., 4., 5., 6.])\nprint(t) #  1차원 텐서인 벡터를 만든다.\n\nprint(t.dim())  # rank. 즉, 차원\nprint(t.shape)  # shape\nprint(t.size()) # shape\n\ntensor([0., 1., 2., 3., 4., 5., 6.])\n1\ntorch.Size([7])\ntorch.Size([7])\n\n\n\n고급 인덱싱이 가능\n\n\nprint(t[0], t[1], t[-1])  # 인덱스로 접근\nprint(t[2:5], t[4:-1])    # 슬라이싱\nprint(t[:2], t[3:])       # 슬라이싱\n\ntensor(0.) tensor(1.) tensor(6.)\ntensor([2., 3., 4.]) tensor([4., 5.])\ntensor([0., 1.]) tensor([3., 4., 5., 6.])"
  },
  {
    "objectID": "posts/PT3.html#텐서-api",
    "href": "posts/PT3.html#텐서-api",
    "title": "파이토치 딥러닝 마스터 3장",
    "section": "",
    "text": "텐서끼리의 연산 대부분은 torch모듈 에 존재하며 대부분이 텐서 객체에 대해 메소드처럼 호출할 수 있다."
  },
  {
    "objectID": "posts/PT3.html#텐서를-저장소-관점으로-생각해보기",
    "href": "posts/PT3.html#텐서를-저장소-관점으로-생각해보기",
    "title": "파이토치 딥러닝 마스터 3장",
    "section": "",
    "text": "텐서의 내부 값은 실제로는 torch.Storage인스턴스 로 관리하며 연속적인 메모리 조각으로 할당된 상태이다.\n저장 공간은 숫자 데이터를 가진 1차원 배열이다.\n\n- 여기서 중요한 점은 서로 다른 방식으로 구성된 텐서가 동일한 메모리 공간을 가리키고 있을 수 있으나, 동일한 데이터에 대해 다른 텐서 뷰를 만드는 작업은 Storage 객체가 관리하는 데이터 크기에 상관없이 빠르게 수행된다는 점이다.\n\n텐서의 저장공간 접근 확인을 위한 간단한 코드\n\n\n#텐서 저장 공간 접근\npoints = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\npoints.storage()\n\n 4.0\n 1.0\n 5.0\n 3.0\n 2.0\n 1.0\n[torch.storage.TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n\n\n\n#텐서를 거치지 않고 저장 공간을 직접 접근하는 방법 \n\npoints_storage = points.storage()\npoints_storage[0]\n\n4.0"
  },
  {
    "objectID": "posts/PT3.html#텐서-메타데이터-사이즈-오프셋-스트라이드",
    "href": "posts/PT3.html#텐서-메타데이터-사이즈-오프셋-스트라이드",
    "title": "파이토치 딥러닝 마스터 3장",
    "section": "",
    "text": "저장 공간을 인덱스로 접근하기 위해 텐서는 저장 공간에 포함된 몇 가지 명확한 정보, 즉 사이즈(size), 오프셋(offset), 스트라이드(stride) 에 의존한다.\n\n\n사이즈(size) : 텐서의 각 차원 별로 들어가는 요소의 수를 표시한 튜플\n오프셋(offset) : 텐서의 첫 번째 요소를 가리키는 색인 값과 동일\n스트라이드(stride) : 각 차원에서 다음 요소를 가리키고 싶을 때 실제 저장 공간상에서 몇 개의 요소를 건너뛰어야하는지를 알려주는 요소"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PyTorch_intro",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nFeb 7, 2024\n\n\n파이토치 딥러닝 마스터 2장\n\n\n유성준 \n\n\n\n\nFeb 7, 2024\n\n\n파이토치 딥러닝 마스터 3장\n\n\n유성준 \n\n\n\n\nFeb 6, 2024\n\n\n파이토치 딥러닝 마스터 1장\n\n\n딥러닝과 파이토치 라이브러리 소개\n\n\n\n\n\nNo matching items"
  }
]