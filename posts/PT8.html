<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="유성준">
<meta name="dcterms.date" content="2024-03-04">

<title>PyTorch_intro - 파이토치 딥러닝 마스터 8장</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">PyTorch_intro</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll me-auto">
  <li class="nav-item">
    <a class="nav-link" href="https://sjoon0305.github.io/sj_hub/" rel="" target="">
 <span class="menu-text">Main_Blog</span></a>
  </li>  
</ul>
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/sjoon0305" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">파이토치 딥러닝 마스터 8장</h1>
                                <div class="quarto-categories">
                <div class="quarto-category">Deep Learning</div>
                <div class="quarto-category">Python</div>
                <div class="quarto-category">PyTorch</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>유성준 </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 4, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="장컨볼루션을-활용한-일반화" class="level1">
<h1>8장:컨볼루션을 활용한 일반화</h1>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%</span>matplotlib inline</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> matplotlib <span class="im">import</span> pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> collections</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn <span class="im">as</span> nn</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.optim <span class="im">as</span> optim</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>torch.set_printoptions(edgeitems<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>torch.manual_seed(<span class="dv">123</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'airplane'</span>,<span class="st">'automobile'</span>,<span class="st">'bird'</span>,<span class="st">'cat'</span>,<span class="st">'deer'</span>,</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>               <span class="st">'dog'</span>,<span class="st">'frog'</span>,<span class="st">'horse'</span>,<span class="st">'ship'</span>,<span class="st">'truck'</span>]</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> torchvision <span class="im">import</span> datasets, transforms</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>data_path <span class="op">=</span> <span class="st">'../data-unversioned/p1ch6/'</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>cifar10 <span class="op">=</span> datasets.CIFAR10(</span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>    data_path, train<span class="op">=</span><span class="va">True</span>, download<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>    transform<span class="op">=</span>transforms.Compose([</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(), <span class="co"># 토텐서 변환</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.4915</span>, <span class="fl">0.4823</span>, <span class="fl">0.4468</span>), <span class="co"># 평균과 표준편차를 가지고 정규화</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                             (<span class="fl">0.2470</span>, <span class="fl">0.2435</span>, <span class="fl">0.2616</span>))</span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>    ]))</span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>cifar10_val <span class="op">=</span> datasets.CIFAR10(</span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>    data_path, train<span class="op">=</span><span class="va">False</span>, download<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>    transform<span class="op">=</span>transforms.Compose([</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>        transforms.ToTensor(),</span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>        transforms.Normalize((<span class="fl">0.4915</span>, <span class="fl">0.4823</span>, <span class="fl">0.4468</span>),</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                             (<span class="fl">0.2470</span>, <span class="fl">0.2435</span>, <span class="fl">0.2616</span>))</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>    ]))</span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>label_map <span class="op">=</span> {<span class="dv">0</span>: <span class="dv">0</span>, <span class="dv">2</span>: <span class="dv">1</span>}</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>class_names <span class="op">=</span> [<span class="st">'airplane'</span>, <span class="st">'bird'</span>]</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>cifar2 <span class="op">=</span> [(img, label_map[label])</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>          <span class="cf">for</span> img, label <span class="kw">in</span> cifar10</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>          <span class="cf">if</span> label <span class="kw">in</span> [<span class="dv">0</span>, <span class="dv">2</span>]]</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>cifar2_val <span class="op">=</span> [(img, label_map[label])</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>              <span class="cf">for</span> img, label <span class="kw">in</span> cifar10_val</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>              <span class="cf">if</span> label <span class="kw">in</span> [<span class="dv">0</span>, <span class="dv">2</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="컨볼루션" class="level2">
<h2 class="anchored" data-anchor-id="컨볼루션">8.1 컨볼루션</h2>
<ul>
<li>비행기 같은 물체와 일치하는 패턴을 인지하려면 인근 픽셀의 배열 방식을 살펴봐야한다</li>
<li>이 개념을 수학적인 형태로 바꾸려면 이미지 내의 다른 픽셀이 아닌 바로 옆 픽셀에 대한 가중치의 합을 계산하면 된다</li>
<li>출력 픽셀 위치마다 가중치 행렬을 만든는 것인데 센터가 되는 픽셀에서 일정 거리 떨어진 경우 가중치가 0이 되는 구조, 계산 결과는 여전히 가중치의 합이므로 선형 연산임</li>
</ul>
<p><code>-</code> translation invariance(평행이동 불변성): 지역화된 패턴이 이미지의 어떤 위치에 있더라도 동일하게 출력에 영향을 주는 성질</p>
<ul>
<li>7장에서 했던 일차원 벡터는 패턴을 찾기 위해선 다소 복잡한 가중치 패턴 구현이 필요</li>
<li>이미지에 대해 지역적인, 평행이동 불변성을 보장하는 선형 연산 -&gt; 컨볼루션</li>
</ul>
<blockquote class="blockquote">
<p>이산 컨볼루션은 2차원 이미지에 가중치 행렬을 스칼라곱을 수행하는 것으로 정의, 가중치 행렬은 <em>커널</em>이라고 부름</p>
</blockquote>
<ul>
<li>커널의 크기는 일반적으로 모든 방향으로 동일하게 만듬</li>
<li>kernel_size = 3</li>
<li>in_ch (입력 피처): RGB 채널을 가지니 픽셀당 3개의 입력 피처</li>
<li>out_ch(출력 피처): 임의로 16을 전달</li>
</ul>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>conv <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>conv</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="6">
<pre><code>Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1))</code></pre>
</div>
</div>
<p><code>-</code> weight 텐서의 차원 정보</p>
<ul>
<li>커널은 3 x 3 이므로 가중치 역시 3 x 3 사용</li>
<li>출력 픽셀 값 하나에 대한 커널: in_ch x 3 x 3</li>
<li>그리고 이 값을 출력 채널만큼 가지게 된다: out_ch = 16</li>
<li>전체 가중치 텐서 out_ch x in_ch x 3 x 3</li>
<li>out_ch x in_ch x kernel_size x kernel_size</li>
</ul>
<div class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>conv.weight.shape, conv.bias.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="4">
<pre><code>(torch.Size([16, 3, 3, 3]), torch.Size([16]))</code></pre>
</div>
</div>
<div class="cell" data-scrolled="true" data-execution_count="7">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 출력 이미지 가중합</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>img, _ <span class="op">=</span> cifar2[<span class="dv">0</span>]</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> conv(img.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>img.unsqueeze(<span class="dv">0</span>).shape, output.shape <span class="co"># 기존 이미지의 차원(C x H x W), 컨볼루션 전달 후 차원</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="7">
<pre><code>(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 30, 30]))</code></pre>
</div>
</div>
<div class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 이미지의 크기가 줄어든 것을 확인할 수 있다.</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">4.8</span>))  <span class="co"># bookskip</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)   <span class="co"># bookskip</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'output'</span>)   <span class="co"># bookskip</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>plt.imshow(output[<span class="dv">0</span>, <span class="dv">0</span>].detach(), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, sharex<span class="op">=</span>ax1, sharey<span class="op">=</span>ax1)  <span class="co"># bookskip</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>plt.imshow(img.mean(<span class="dv">0</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)  <span class="co"># bookskip</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'input'</span>)  <span class="co"># bookskip</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'Ch8_F2_PyTorch.png'</span>)  <span class="co"># bookskip</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PT8_files/figure-html/cell-6-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="경계-패딩하기" class="level2">
<h2 class="anchored" data-anchor-id="경계-패딩하기">8.2 경계 패딩하기</h2>
<ul>
<li>3 x 3 이웃 영역에 대해 컨볼루션 커널을 가중합으로 적용하려면 일단 모든 방향에 값이 존재한다는 가정이 있어야 한다!!</li>
<li>padding=1 을 통해 가짜 픽셀을 패딩한다</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="PT8_files/figure-html/25bd2347-660a-46fa-b118-f238bec7d1d9-1-c772f1bd-fc12-4a49-8182-d158c788bfee.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 패딩시킨 코드 </span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>conv <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> conv(img.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>img.unsqueeze(<span class="dv">0</span>).shape, output.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="8">
<pre><code>(torch.Size([1, 3, 32, 32]), torch.Size([1, 16, 32, 32]))</code></pre>
</div>
</div>
<blockquote class="blockquote">
<p>bias는 0으로 제거해 교란 변수를 배제, 가중치에 상수값을 넣어서 출력에서 각 픽셀이 자신의 이웃 픽셀에 대한 평균을 가지게 해보자</p>
</blockquote>
<div class="cell" data-execution_count="8">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>    conv.bias.zero_()</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    conv.weight.fill_(<span class="fl">1.0</span> <span class="op">/</span> <span class="fl">9.0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="9">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#  가중치는 이웃 픽셀에 대한 평균</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> conv(img.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">4.8</span>))  <span class="co"># bookskip</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)   <span class="co"># bookskip</span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'output'</span>)   <span class="co"># bookskip</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(output[<span class="dv">0</span>, <span class="dv">0</span>].detach(), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, sharex<span class="op">=</span>ax1, sharey<span class="op">=</span>ax1)  <span class="co"># bookskip</span></span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>plt.imshow(img.mean(<span class="dv">0</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)  <span class="co"># bookskip</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'input'</span>)  <span class="co"># bookskip</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'Ch8_F4_PyTorch.png'</span>)  <span class="co"># bookskip</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PT8_files/figure-html/cell-9-output-1.png" class="img-fluid"></p>
</div>
</div>
<div class="cell" data-execution_count="81">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>(<span class="op">-</span><span class="fl">0.2001</span><span class="op">*</span><span class="fl">0.9156</span><span class="op">-</span><span class="fl">0.1735</span><span class="op">*</span><span class="fl">1.4658</span><span class="op">+</span><span class="fl">0.0442</span><span class="op">*</span><span class="fl">0.9604</span><span class="op">+</span><span class="fl">0.0695</span>)<span class="op">/</span><span class="fl">0.0222</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="81">
<pre><code>-14.665683783783782</code></pre>
</div>
</div>
<div class="cell" data-execution_count="74">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>conv <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">1</span>, kernel_size<span class="op">=</span><span class="dv">2</span>, padding<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="75">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a>conv.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="75">
<pre><code>Parameter containing:
tensor([[[[ 0.1812,  0.1955],
          [ 0.1995, -0.2001]],

         [[-0.1721, -0.0878],
          [ 0.0529, -0.1735]],

         [[-0.1613,  0.0608],
          [-0.1309,  0.0442]]]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="76">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>conv.bias</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="76">
<pre><code>Parameter containing:
tensor([0.0222], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="77">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="77">
<pre><code>tensor([[[[ 0.9156,  1.1696,  1.2331,  0.5663],
          [-0.3228,  0.8838,  1.2014,  1.2649],
          [ 1.2966,  0.2011,  0.4869,  1.3125],
          [ 1.0743,  0.4551,  0.5504,  0.9791]],

         [[ 1.4658,  1.8040,  2.0294,  1.1437],
          [ 0.5156,  1.6912,  1.7718,  1.8040],
          [ 1.6107,  0.4995,  1.4658,  1.7718],
          [ 1.1759,  0.9665,  1.2886,  1.6590]],

         [[ 0.9604,  1.1853,  1.4701,  0.3158],
          [-0.7635,  1.2602,  1.3352,  1.0953],
          [ 1.5600,  0.9304,  0.8405,  0.9454],
          [ 1.3502, -0.1189, -0.0140,  0.1059]]]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="73">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>conv(output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="73">
<pre><code>tensor([[[[-0.0695, -0.2537, -0.2587, -0.5608, -0.4635],
          [ 0.0061,  0.4689,  0.4658, -0.0940, -0.5199],
          [ 0.0787,  0.6408,  0.4002,  0.3023, -0.6798],
          [ 0.8647, -0.5524, -0.2736,  0.1320, -0.6747],
          [ 0.3528, -0.2184,  0.2578,  0.4575, -0.1202]]]],
       grad_fn=&lt;ConvolutionBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="30">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>img.unsqueeze(<span class="dv">0</span>).shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="30">
<pre><code>torch.Size([1, 3, 32, 32])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>conv(img.unsqueeze(<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="31">
<pre><code>tensor([[[[ 0.3902,  0.2728,  ...,  0.3474,  0.1872],
          [ 0.3793,  0.1530,  ...,  0.1958,  0.0754],
          ...,
          [-0.0650,  0.0541,  ...,  0.0807,  0.2762],
          [ 0.1024,  0.3440,  ..., -0.0268,  0.1232]]]],
       grad_fn=&lt;ConvolutionBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="68">
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>conv <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">1</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> torch.no_grad():</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>    conv.weight[:] <span class="op">=</span> torch.tensor([[<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>],</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>                                   [<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>],</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>                                   [<span class="op">-</span><span class="fl">1.0</span>, <span class="fl">0.0</span>, <span class="fl">1.0</span>]])</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>    conv.bias.zero_()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="69">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a>pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">8</span>)</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> pool(img.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>output.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="69">
<pre><code>torch.Size([1, 3, 4, 4])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="57">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span class="fl">1.1696</span><span class="op">+</span><span class="fl">0.8838</span><span class="op">+</span><span class="fl">1.8040</span><span class="op">+</span><span class="fl">1.6912</span><span class="op">+</span><span class="fl">1.1853</span><span class="op">+</span><span class="fl">1.2602</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="57">
<pre><code>7.9941</code></pre>
</div>
</div>
<div class="cell" data-execution_count="54">
<div class="sourceCode cell-code" id="cb33"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a>output</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="54">
<pre><code>tensor([[[[ 0.9156,  1.1696,  1.2331,  0.5663],
          [-0.3228,  0.8838,  1.2014,  1.2649],
          [ 1.2966,  0.2011,  0.4869,  1.3125],
          [ 1.0743,  0.4551,  0.5504,  0.9791]],

         [[ 1.4658,  1.8040,  2.0294,  1.1437],
          [ 0.5156,  1.6912,  1.7718,  1.8040],
          [ 1.6107,  0.4995,  1.4658,  1.7718],
          [ 1.1759,  0.9665,  1.2886,  1.6590]],

         [[ 0.9604,  1.1853,  1.4701,  0.3158],
          [-0.7635,  1.2602,  1.3352,  1.0953],
          [ 1.5600,  0.9304,  0.8405,  0.9454],
          [ 1.3502, -0.1189, -0.0140,  0.1059]]]])</code></pre>
</div>
</div>
<div class="cell" data-execution_count="55">
<div class="sourceCode cell-code" id="cb35"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a>conv.weight</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="55">
<pre><code>Parameter containing:
tensor([[[[-1.,  0.,  1.],
          [-1.,  0.,  1.],
          [-1.,  0.,  1.]],

         [[-1.,  0.,  1.],
          [-1.,  0.,  1.],
          [-1.,  0.,  1.]],

         [[-1.,  0.,  1.],
          [-1.,  0.,  1.],
          [-1.,  0.,  1.]]]], requires_grad=True)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="56">
<div class="sourceCode cell-code" id="cb37"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a>conv(output)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="56">
<pre><code>tensor([[[[  7.9941,   6.2700,  -1.8042,  -9.0409],
          [  9.6251,   4.5957,   0.5945, -11.8341],
          [  6.7690,   1.4295,   4.1689,  -8.9265],
          [  2.9337,  -3.4496,   3.8400,  -4.6182]]]],
       grad_fn=&lt;ConvolutionBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 가로로 인접한 두 영역 사이의 수직 경계를 탐색하는 가중치</span></span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> conv(img.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="fl">4.8</span>))  <span class="co"># bookskip</span></span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>ax1 <span class="op">=</span> plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">1</span>)   <span class="co"># bookskip</span></span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'output'</span>)   <span class="co"># bookskip</span></span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>plt.imshow(output[<span class="dv">0</span>, <span class="dv">0</span>].detach(), cmap<span class="op">=</span><span class="st">'gray'</span>)</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>plt.subplot(<span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">2</span>, sharex<span class="op">=</span>ax1, sharey<span class="op">=</span>ax1)  <span class="co"># bookskip</span></span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>plt.imshow(img.mean(<span class="dv">0</span>), cmap<span class="op">=</span><span class="st">'gray'</span>)  <span class="co"># bookskip</span></span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'input'</span>)  <span class="co"># bookskip</span></span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>plt.savefig(<span class="st">'Ch8_F4_PyTorch.png'</span>)  <span class="co"># bookskip</span></span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<p><img src="PT8_files/figure-html/cell-24-output-1.png" class="img-fluid"></p>
</div>
</div>
</section>
<section id="이미지가-매우-클-때는" class="level2">
<h2 class="anchored" data-anchor-id="이미지가-매우-클-때는">이미지가 매우 클 때는?</h2>
<blockquote class="blockquote">
<p>kernel_size가 3 또는 5를 사용했는데 이미지가 크다면 지역성의 한계를 가진다</p>
</blockquote>
<ol type="1">
<li>더 큰 컨볼루션 커널을 사용 -&gt; 컨볼루션의 장점을 잃어버리게 된다.</li>
<li>다운샘플링!</li>
</ol>
<p><code>-</code> 다운샘플링 - 네 개의 픽셀을 평균: 초기에는 평균 풀링을 많이 사용했지만 요즘은 잘 사용하지 않는다 - 네 개의 픽셀 중 최댓값: 맥스 풀링은 요즘에 많이 사용하지만, 데이터의 3/4을 버린다는 단점 - 맥스 풀링: nn.MaxPool2d 모듈에 있다. 입력으로 풀링 연산을 수행할 인접한 영역 크기를 받음 - nn.MaxPool2d(2) -&gt; 크기를 절반으로 줄임</p>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="co"># pool은 이미지 절반으로 줄인다</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>pool <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>)</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>output <span class="op">=</span> pool(img.unsqueeze(<span class="dv">0</span>))</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>img.unsqueeze(<span class="dv">0</span>).shape, output.shape</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>(torch.Size([1, 3, 32, 32]), torch.Size([1, 3, 16, 16]))</code></pre>
</div>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="PT8_files/figure-html/b6424187-fd2c-4fbe-b275-c1fa8cefc2dd-1-730185ee-bb11-4c06-9128-d3067a3f2f96.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<blockquote class="blockquote">
<p>더 나은 성능을 위해 컨볼루션과 다운샘플링 결합</p>
</blockquote>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="PT8_files/figure-html/f903dac2-c5a3-49ef-8ad5-4dafd3321b7c-1-a24e610d-070f-4c06-85ad-5c4cf3e8dc39.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">image.png</figcaption>
</figure>
</div>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">16</span>, <span class="dv">8</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ...</span></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a>            )</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb43"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb43-2"><a href="#cb43-2" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb43-3"><a href="#cb43-3" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb43-4"><a href="#cb43-4" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb43-5"><a href="#cb43-5" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">16</span>, <span class="dv">8</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>), <span class="co"># 8개 채널로 출력</span></span>
<span id="cb43-6"><a href="#cb43-6" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb43-7"><a href="#cb43-7" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb43-8"><a href="#cb43-8" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ... 뭔가 중요한게 하나 빠졌다!</span></span>
<span id="cb43-9"><a href="#cb43-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>, <span class="dv">32</span>), <span class="co"># 8</span></span>
<span id="cb43-10"><a href="#cb43-10" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb43-11"><a href="#cb43-11" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>선형 계층의 크기가 MaxPool2d의 출력 크기 8 x 8 x 8 에 의존</li>
<li>(C x H x W 구조) 초기: 3 x 32 x 32 -&gt; (두 번의 맥스 풀링, 마지막 Conv2d의 출력 피처:8) 8 x 8 x 8</li>
<li></li>
</ul>
<div class="cell" data-scrolled="true" data-execution_count="9">
<div class="sourceCode cell-code" id="cb44"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a>model(img.unsqueeze(<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="9">
<pre><code>tensor([[0.0908, 0.0938]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<ul>
<li>RuntimeError: mat1 and mat2 shapes cannot be multiplied (64x8 and 512x32)</li>
<li>위같은 에러가 생기는 이유는 8 x 8 이미지를 512요소를 가진 1차원 벡터로 차원 정보를 변경해야 한다</li>
</ul>
</section>
<section id="nn.module-서브클래싱하기" class="level2">
<h2 class="anchored" data-anchor-id="nn.module-서브클래싱하기">8.3 nn.Module 서브클래싱하기</h2>
<ul>
<li>이번 절의 핵심내용은 nn.Module의 서브클래스를 직접 만드는 법을 배워서 이미 만들어져 있는 것이나 nn.Sequential처럼 사용한다</li>
<li>nn.Module을 서브클래싱하려면 먼저 forward 함수를 정의하여 모듈로 입력을 전달하고 출력을 전달하게 해야 한다</li>
<li>torch 연산을 사용하기만 한다면 자동미분 기능이 자동으로 역방향 경로를 만들어준다.</li>
<li>그래서 nn.Module에는 backward가 필요 없다</li>
</ul>
<blockquote class="blockquote">
<p>뒤에서 만들 연산도 결국은 컨볼루션 같은 이미 있는 모듈을 사용한다. 이 서브 모듈을 포함하려면 생성자 __init__에 정의하고 self에 할당해서 forward 함수에서 사용할 수 있게 만들어야 한다.</p>
</blockquote>
<ul>
<li>이렇게 하면 모듈이 동작하는 동안 파라미터가 유지될 것이다. 모든 코드에 앞서 super().init__()를 호출해야 한다!</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb46"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> nn.Sequential(</span>
<span id="cb46-2"><a href="#cb46-2" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb46-3"><a href="#cb46-3" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb46-4"><a href="#cb46-4" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb46-5"><a href="#cb46-5" aria-hidden="true" tabindex="-1"></a>            nn.Conv2d(<span class="dv">16</span>, <span class="dv">8</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>),</span>
<span id="cb46-6"><a href="#cb46-6" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb46-7"><a href="#cb46-7" aria-hidden="true" tabindex="-1"></a>            nn.MaxPool2d(<span class="dv">2</span>),</span>
<span id="cb46-8"><a href="#cb46-8" aria-hidden="true" tabindex="-1"></a>            <span class="co"># ... 무언가가 빠졌다.</span></span>
<span id="cb46-9"><a href="#cb46-9" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>, <span class="dv">32</span>),</span>
<span id="cb46-10"><a href="#cb46-10" aria-hidden="true" tabindex="-1"></a>            nn.Tanh(),</span>
<span id="cb46-11"><a href="#cb46-11" aria-hidden="true" tabindex="-1"></a>            nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="PT8_files/figure-html/0c9d7b2c-c7fb-469d-a432-12b49d345ba6-1-d69a72b3-9a4f-4058-a6d3-d238cc9aa692.png" class="img-fluid"></p>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb47"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Net(nn.Module):  <span class="co"># Net 클래스는 nn.Sequential과 같은 서브모듈</span></span>
<span id="cb47-2"><a href="#cb47-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb47-3"><a href="#cb47-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>() <span class="co"># 모든 코드의 앞에서 필수!!</span></span>
<span id="cb47-4"><a href="#cb47-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-5"><a href="#cb47-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act1 <span class="op">=</span> nn.Tanh()</span>
<span id="cb47-6"><a href="#cb47-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool1 <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>)</span>
<span id="cb47-7"><a href="#cb47-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">16</span>, <span class="dv">8</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb47-8"><a href="#cb47-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act2 <span class="op">=</span> nn.Tanh()</span>
<span id="cb47-9"><a href="#cb47-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.pool2 <span class="op">=</span> nn.MaxPool2d(<span class="dv">2</span>)</span>
<span id="cb47-10"><a href="#cb47-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>, <span class="dv">32</span>)</span>
<span id="cb47-11"><a href="#cb47-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.act3 <span class="op">=</span> nn.Tanh()</span>
<span id="cb47-12"><a href="#cb47-12" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>)</span>
<span id="cb47-13"><a href="#cb47-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb47-14"><a href="#cb47-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb47-15"><a href="#cb47-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.pool1(<span class="va">self</span>.act1(<span class="va">self</span>.conv1(x)))</span>
<span id="cb47-16"><a href="#cb47-16" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.pool2(<span class="va">self</span>.act2(<span class="va">self</span>.conv2(out)))</span>
<span id="cb47-17"><a href="#cb47-17" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>) <span class="co"># 앞에서 놓쳤던 차원 정보 변경</span></span>
<span id="cb47-18"><a href="#cb47-18" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.act3(<span class="va">self</span>.fc1(out))</span>
<span id="cb47-19"><a href="#cb47-19" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc2(out)</span>
<span id="cb47-20"><a href="#cb47-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><img src="PT8_files/figure-html/1599c594-d617-42bc-8f74-9da6d39ddedf-1-afde53d3-5636-4bc4-9f1b-3e55bb92df6c.png" class="img-fluid"></p>
<blockquote class="blockquote">
<p>앞에서 정의한 Net과 동일하면서도 훨씬 더 간결하다. 생성자에서의 초기화를 위한 파라미터 입력은 필요</p>
</blockquote>
<div class="cell" data-execution_count="10">
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch.nn.functional <span class="im">as</span> F</span>
<span id="cb48-2"><a href="#cb48-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb48-3"><a href="#cb48-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Net(nn.Module):</span>
<span id="cb48-4"><a href="#cb48-4" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>):</span>
<span id="cb48-5"><a href="#cb48-5" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb48-6"><a href="#cb48-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, <span class="dv">16</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>) <span class="co"># 컨볼루션 3C -&gt; 16C 로 변환</span></span>
<span id="cb48-7"><a href="#cb48-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(<span class="dv">16</span>, <span class="dv">8</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>) <span class="co"># 컨볼루션 16C -&gt; 8C 로 변환</span></span>
<span id="cb48-8"><a href="#cb48-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>, <span class="dv">32</span>) <span class="co"># 선형 변환</span></span>
<span id="cb48-9"><a href="#cb48-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>) <span class="co"># 선형 변환</span></span>
<span id="cb48-10"><a href="#cb48-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb48-11"><a href="#cb48-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb48-12"><a href="#cb48-12" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.tanh(<span class="va">self</span>.conv1(x)), <span class="dv">2</span>) <span class="co"># 컨볼루션 -&gt; 활성함수(tanh) -&gt; 맥스풀링(2)</span></span>
<span id="cb48-13"><a href="#cb48-13" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.tanh(<span class="va">self</span>.conv2(out)), <span class="dv">2</span>) <span class="co"># 컨볼루션 -&gt; 활성함수(tanh) -&gt; 맥스풀링(2)</span></span>
<span id="cb48-14"><a href="#cb48-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span>) <span class="co"># 차원정보 맞추기 8C x 8 x 8 -&gt; 512d</span></span>
<span id="cb48-15"><a href="#cb48-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.tanh(<span class="va">self</span>.fc1(out))  <span class="co"># 선형변환 -&gt; 활성함수(tanh)</span></span>
<span id="cb48-16"><a href="#cb48-16" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc2(out) <span class="co"># 최종 선형변환(2개의 아웃풋)</span></span>
<span id="cb48-17"><a href="#cb48-17" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li><code>__init__(self)</code> 메서드는 주로 객체가 생성될 때 초기화 작업을 수행하는데 사용</li>
<li>여기서는 주로 뉴럴 네트워크의 각 레이어들을 정의하고 초기화하는 역할</li>
</ul>
<blockquote class="blockquote">
<p>따라서 <code>__init__</code> 메서드는 보통 신경망의 레이어를 선언하고 초기화하는 부분으로 생각할 수 있습니다. 반면에 forward 메서드에서는 이러한 레이어들을 통과하면서 입력에서 출력까지의 계산과정이 구현되어 있습니다.</p>
</blockquote>
<div class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb49"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델 점검</span></span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Net()</span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a>model(img.unsqueeze(<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>tensor([[-0.0139,  0.1372]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
</section>
<section id="컨볼루션-신경망-훈련시키기" class="level2">
<h2 class="anchored" data-anchor-id="컨볼루션-신경망-훈련시키기">8.4 컨볼루션 신경망 훈련시키기</h2>
<ol type="1">
<li>모델에 입력값 입력(순방향)</li>
<li>손실값 계산(순방향)</li>
<li>이전 기울기값 0으로 리셋</li>
<li>loss.backward() 호출하여 모든 파라미터에 대한 손실값의 기울기를 계산(역방향)</li>
<li>이후 옵티마이저를 통해 손실값을 낮추도록 파라미터를 조정</li>
</ol>
<div class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Net()</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>model(img.unsqueeze(<span class="dv">0</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="12">
<pre><code>tensor([[0.2268, 0.2497]], grad_fn=&lt;AddmmBackward0&gt;)</code></pre>
</div>
</div>
<div class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(cifar2, batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb53-2"><a href="#cb53-2" aria-hidden="true" tabindex="-1"></a>                                           shuffle<span class="op">=</span><span class="va">True</span>)  </span>
<span id="cb53-3"><a href="#cb53-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-4"><a href="#cb53-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Net()  <span class="co">#  신경망 초기화</span></span>
<span id="cb53-5"><a href="#cb53-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">1e-2</span>)  <span class="co">#  경사 하강법</span></span>
<span id="cb53-6"><a href="#cb53-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()  <span class="co">#  크로스엔트로피 손실값(LogSoftmax와 NLLLoss의 조합)</span></span>
<span id="cb53-7"><a href="#cb53-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb53-8"><a href="#cb53-8" aria-hidden="true" tabindex="-1"></a>training_loop(  <span class="co"># 훈련 루프 호출</span></span>
<span id="cb53-9"><a href="#cb53-9" aria-hidden="true" tabindex="-1"></a>    n_epochs <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb53-10"><a href="#cb53-10" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optimizer,</span>
<span id="cb53-11"><a href="#cb53-11" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model,</span>
<span id="cb53-12"><a href="#cb53-12" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> loss_fn,</span>
<span id="cb53-13"><a href="#cb53-13" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> train_loader,</span>
<span id="cb53-14"><a href="#cb53-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2024-03-07 14:27:50.762727 Epoch 1, Training loss 0.5920039126827459
2024-03-07 14:27:57.233376 Epoch 10, Training loss 0.3260749121000812
2024-03-07 14:28:04.245433 Epoch 20, Training loss 0.2971180685006889
2024-03-07 14:28:11.297717 Epoch 30, Training loss 0.27208930899383155
2024-03-07 14:28:18.794419 Epoch 40, Training loss 0.25611254653543425
2024-03-07 14:28:26.076065 Epoch 50, Training loss 0.23912156472919852
2024-03-07 14:28:33.461875 Epoch 60, Training loss 0.22134561794009178
2024-03-07 14:28:40.881375 Epoch 70, Training loss 0.20697098775843906
2024-03-07 14:28:48.126675 Epoch 80, Training loss 0.19211664933497738
2024-03-07 14:28:55.208202 Epoch 90, Training loss 0.176260754347417
2024-03-07 14:29:02.376236 Epoch 100, Training loss 0.1619067371461042</code></pre>
</div>
</div>
<div class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="annotated-cell-35"><pre class="sourceCode python code-annotation-code code-with-copy"><code class="sourceCode python"><span id="annotated-cell-35-1"><a href="#annotated-cell-35-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 정확도 측정</span></span>
<span id="annotated-cell-35-2"><a href="#annotated-cell-35-2" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(cifar2, batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="annotated-cell-35-3"><a href="#annotated-cell-35-3" aria-hidden="true" tabindex="-1"></a>                                           shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="annotated-cell-35-4"><a href="#annotated-cell-35-4" aria-hidden="true" tabindex="-1"></a>val_loader <span class="op">=</span> torch.utils.data.DataLoader(cifar2_val, batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="annotated-cell-35-5"><a href="#annotated-cell-35-5" aria-hidden="true" tabindex="-1"></a>                                         shuffle<span class="op">=</span><span class="va">False</span>)</span>
<span id="annotated-cell-35-6"><a href="#annotated-cell-35-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-35-7"><a href="#annotated-cell-35-7" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> validate(model, train_loader, val_loader):</span>
<span id="annotated-cell-35-8"><a href="#annotated-cell-35-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> name, loader <span class="kw">in</span> [(<span class="st">"train"</span>, train_loader), (<span class="st">"val"</span>, val_loader)]:</span>
<span id="annotated-cell-35-9"><a href="#annotated-cell-35-9" aria-hidden="true" tabindex="-1"></a>        correct <span class="op">=</span> <span class="dv">0</span></span>
<span id="annotated-cell-35-10"><a href="#annotated-cell-35-10" aria-hidden="true" tabindex="-1"></a>        total <span class="op">=</span> <span class="dv">0</span></span>
<span id="annotated-cell-35-11"><a href="#annotated-cell-35-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-35-12"><a href="#annotated-cell-35-12" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="annotated-cell-35-13"><a href="#annotated-cell-35-13" aria-hidden="true" tabindex="-1"></a>            <span class="cf">for</span> imgs, labels <span class="kw">in</span> loader:</span>
<span id="annotated-cell-35-14"><a href="#annotated-cell-35-14" aria-hidden="true" tabindex="-1"></a>                outputs <span class="op">=</span> model(imgs)</span>
<span id="annotated-cell-35-15"><a href="#annotated-cell-35-15" aria-hidden="true" tabindex="-1"></a>                _, predicted <span class="op">=</span> torch.<span class="bu">max</span>(outputs, dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="annotated-cell-35-16"><a href="#annotated-cell-35-16" aria-hidden="true" tabindex="-1"></a>                total <span class="op">+=</span> labels.shape[<span class="dv">0</span>]</span>
<span id="annotated-cell-35-17"><a href="#annotated-cell-35-17" aria-hidden="true" tabindex="-1"></a>                correct <span class="op">+=</span> <span class="bu">int</span>((predicted <span class="op">==</span> labels).<span class="bu">sum</span>())</span>
<span id="annotated-cell-35-18"><a href="#annotated-cell-35-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-35-19"><a href="#annotated-cell-35-19" aria-hidden="true" tabindex="-1"></a>        <span class="bu">print</span>(<span class="st">"Accuracy </span><span class="sc">{}</span><span class="st">: </span><span class="sc">{:.2f}</span><span class="st">"</span>.<span class="bu">format</span>(name , correct <span class="op">/</span> total))</span>
<span id="annotated-cell-35-20"><a href="#annotated-cell-35-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-35-21"><a href="#annotated-cell-35-21" aria-hidden="true" tabindex="-1"></a>validate(model, train_loader, val_loader)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Accuracy train: 0.92
Accuracy val: 0.88</code></pre>
</div>
</div>
</section>
<section id="모델을-저장하고-불러오기" class="level2">
<h2 class="anchored" data-anchor-id="모델을-저장하고-불러오기">모델을 저장하고 불러오기</h2>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb56"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 저장</span></span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a>torch.save(model.state_dict(), data_path <span class="op">+</span> <span class="st">'birds_vs_airplanes.pt'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="annotated-cell-37"><pre class="sourceCode python code-annotation-code code-with-copy"><code class="sourceCode python"><span id="annotated-cell-37-1"><a href="#annotated-cell-37-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 불러오기</span></span>
<span id="annotated-cell-37-2"><a href="#annotated-cell-37-2" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> Net()</span>
<span id="annotated-cell-37-3"><a href="#annotated-cell-37-3" aria-hidden="true" tabindex="-1"></a>loaded_model.load_state_dict(torch.load(data_path</span>
<span id="annotated-cell-37-4"><a href="#annotated-cell-37-4" aria-hidden="true" tabindex="-1"></a>                                        <span class="op">+</span> <span class="st">'birds_vs_airplanes.pt'</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>&lt;All keys matched successfully&gt;</code></pre>
</div>
</div>
</section>
<section id="gpu에서-훈련시키기" class="level2">
<h2 class="anchored" data-anchor-id="gpu에서-훈련시키기">GPU에서 훈련시키기</h2>
<ul>
<li>nn.Module도 .to 메소드가 있어서 모든 파라미터를 GPU로 옮길 수 있다</li>
<li></li>
</ul>
<div class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb58"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="co"># device 변수 설정</span></span>
<span id="cb58-2"><a href="#cb58-2" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> (torch.device(<span class="st">'cuda'</span>) <span class="cf">if</span> torch.cuda.is_available()</span>
<span id="cb58-3"><a href="#cb58-3" aria-hidden="true" tabindex="-1"></a>          <span class="cf">else</span> torch.device(<span class="st">'cpu'</span>))</span>
<span id="cb58-4"><a href="#cb58-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb58-5"><a href="#cb58-5" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"Training on device </span><span class="sc">{</span>device<span class="sc">}</span><span class="ss">."</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Training on device cuda.</code></pre>
</div>
</div>
<div class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb60"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb60-2"><a href="#cb60-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-3"><a href="#cb60-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> training_loop(n_epochs, optimizer, model, loss_fn, train_loader):</span>
<span id="cb60-4"><a href="#cb60-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb60-5"><a href="#cb60-5" aria-hidden="true" tabindex="-1"></a>        loss_train <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb60-6"><a href="#cb60-6" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb60-7"><a href="#cb60-7" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> imgs, labels <span class="kw">in</span> train_loader:</span>
<span id="cb60-8"><a href="#cb60-8" aria-hidden="true" tabindex="-1"></a>            imgs <span class="op">=</span> imgs.to(device<span class="op">=</span>device)  <span class="co"># imgs와 labels를 옮기는 이 두 줄만 다르다</span></span>
<span id="cb60-9"><a href="#cb60-9" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device<span class="op">=</span>device)</span>
<span id="cb60-10"><a href="#cb60-10" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(imgs)</span>
<span id="cb60-11"><a href="#cb60-11" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(outputs, labels)</span>
<span id="cb60-12"><a href="#cb60-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-13"><a href="#cb60-13" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb60-14"><a href="#cb60-14" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb60-15"><a href="#cb60-15" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb60-16"><a href="#cb60-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-17"><a href="#cb60-17" aria-hidden="true" tabindex="-1"></a>            loss_train <span class="op">+=</span> loss.item()</span>
<span id="cb60-18"><a href="#cb60-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb60-19"><a href="#cb60-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">==</span> <span class="dv">1</span> <span class="kw">or</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb60-20"><a href="#cb60-20" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'</span><span class="sc">{}</span><span class="st"> Epoch </span><span class="sc">{}</span><span class="st">, Training loss </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb60-21"><a href="#cb60-21" aria-hidden="true" tabindex="-1"></a>                datetime.datetime.now(), epoch,</span>
<span id="cb60-22"><a href="#cb60-22" aria-hidden="true" tabindex="-1"></a>                loss_train <span class="op">/</span> <span class="bu">len</span>(train_loader)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>train_loader <span class="op">=</span> torch.utils.data.DataLoader(cifar2, batch_size<span class="op">=</span><span class="dv">64</span>,</span>
<span id="cb61-2"><a href="#cb61-2" aria-hidden="true" tabindex="-1"></a>                                           shuffle<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb61-3"><a href="#cb61-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-4"><a href="#cb61-4" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> Net().to(device<span class="op">=</span>device)  <span class="co"># 모델(파라미터)을 GPU로 옮긴다</span></span>
<span id="cb61-5"><a href="#cb61-5" aria-hidden="true" tabindex="-1"></a>optimizer <span class="op">=</span> optim.SGD(model.parameters(), lr<span class="op">=</span><span class="fl">1e-2</span>)</span>
<span id="cb61-6"><a href="#cb61-6" aria-hidden="true" tabindex="-1"></a>loss_fn <span class="op">=</span> nn.CrossEntropyLoss()</span>
<span id="cb61-7"><a href="#cb61-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb61-8"><a href="#cb61-8" aria-hidden="true" tabindex="-1"></a>training_loop(</span>
<span id="cb61-9"><a href="#cb61-9" aria-hidden="true" tabindex="-1"></a>    n_epochs <span class="op">=</span> <span class="dv">100</span>,</span>
<span id="cb61-10"><a href="#cb61-10" aria-hidden="true" tabindex="-1"></a>    optimizer <span class="op">=</span> optimizer,</span>
<span id="cb61-11"><a href="#cb61-11" aria-hidden="true" tabindex="-1"></a>    model <span class="op">=</span> model,</span>
<span id="cb61-12"><a href="#cb61-12" aria-hidden="true" tabindex="-1"></a>    loss_fn <span class="op">=</span> loss_fn,</span>
<span id="cb61-13"><a href="#cb61-13" aria-hidden="true" tabindex="-1"></a>    train_loader <span class="op">=</span> train_loader,</span>
<span id="cb61-14"><a href="#cb61-14" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>2024-03-07 14:34:04.002323 Epoch 1, Training loss 0.5633499166768068
2024-03-07 14:34:06.638765 Epoch 10, Training loss 0.32738773534252386
2024-03-07 14:34:09.595797 Epoch 20, Training loss 0.29067508349562904
2024-03-07 14:34:12.572088 Epoch 30, Training loss 0.26694642757154574
2024-03-07 14:34:15.544828 Epoch 40, Training loss 0.24837728585027585
2024-03-07 14:34:18.628061 Epoch 50, Training loss 0.2286462817507185
2024-03-07 14:34:21.607041 Epoch 60, Training loss 0.214210810317735
2024-03-07 14:34:24.608404 Epoch 70, Training loss 0.19998175247459654
2024-03-07 14:34:27.688660 Epoch 80, Training loss 0.18903309752227396
2024-03-07 14:34:30.660003 Epoch 90, Training loss 0.17515257385316169
2024-03-07 14:34:33.664524 Epoch 100, Training loss 0.16278002166729064</code></pre>
</div>
</div>
<ul>
<li>신경망이 작음에도 불구하고 GPU를 사용했더니 속더가 개선됐다</li>
<li>GPU 연산은 크기가 큰 모델에서 그 장점이 확연히 드러난다</li>
</ul>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># 모델을 불러올 때 map_location 키워드를 전달</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a>loaded_model <span class="op">=</span> Net().to(device<span class="op">=</span>device)</span>
<span id="cb63-3"><a href="#cb63-3" aria-hidden="true" tabindex="-1"></a>loaded_model.load_state_dict(torch.load(data_path</span>
<span id="cb63-4"><a href="#cb63-4" aria-hidden="true" tabindex="-1"></a>                                        <span class="op">+</span> <span class="st">'birds_vs_airplanes.pt'</span>,</span>
<span id="cb63-5"><a href="#cb63-5" aria-hidden="true" tabindex="-1"></a>                                        map_location<span class="op">=</span>device))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="정규화모델이-수렴하고-일반화하도록-돕는-방법" class="level2">
<h2 class="anchored" data-anchor-id="정규화모델이-수렴하고-일반화하도록-돕는-방법">정규화:모델이 수렴하고 일반화하도록 돕는 방법</h2>
<section id="가중치-페널티" class="level3">
<h3 class="anchored" data-anchor-id="가중치-페널티">1. 가중치 페널티</h3>
<ul>
<li>L1 정규화: Mahattan Distance, 택시거리, 가중치의 절대값의 합</li>
<li>L2 정규화: 두 벡터 사이의 직선거리, 가중치 감쇠</li>
</ul>
<div class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb64"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-2"><a href="#cb64-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> training_loop_l2reg(n_epochs, optimizer, model, loss_fn,</span>
<span id="cb64-3"><a href="#cb64-3" aria-hidden="true" tabindex="-1"></a>                        train_loader):</span>
<span id="cb64-4"><a href="#cb64-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> epoch <span class="kw">in</span> <span class="bu">range</span>(<span class="dv">1</span>, n_epochs <span class="op">+</span> <span class="dv">1</span>):</span>
<span id="cb64-5"><a href="#cb64-5" aria-hidden="true" tabindex="-1"></a>        loss_train <span class="op">=</span> <span class="fl">0.0</span></span>
<span id="cb64-6"><a href="#cb64-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> imgs, labels <span class="kw">in</span> train_loader:</span>
<span id="cb64-7"><a href="#cb64-7" aria-hidden="true" tabindex="-1"></a>            imgs <span class="op">=</span> imgs.to(device<span class="op">=</span>device)</span>
<span id="cb64-8"><a href="#cb64-8" aria-hidden="true" tabindex="-1"></a>            labels <span class="op">=</span> labels.to(device<span class="op">=</span>device)</span>
<span id="cb64-9"><a href="#cb64-9" aria-hidden="true" tabindex="-1"></a>            outputs <span class="op">=</span> model(imgs)</span>
<span id="cb64-10"><a href="#cb64-10" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss_fn(outputs, labels)</span>
<span id="cb64-11"><a href="#cb64-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-12"><a href="#cb64-12" aria-hidden="true" tabindex="-1"></a>            l2_lambda <span class="op">=</span> <span class="fl">0.001</span></span>
<span id="cb64-13"><a href="#cb64-13" aria-hidden="true" tabindex="-1"></a>            l2_norm <span class="op">=</span> <span class="bu">sum</span>(p.<span class="bu">pow</span>(<span class="fl">2.0</span>).<span class="bu">sum</span>()</span>
<span id="cb64-14"><a href="#cb64-14" aria-hidden="true" tabindex="-1"></a>                          <span class="cf">for</span> p <span class="kw">in</span> model.parameters())  <span class="co"># L1 정규화라면 pow(2.0)-&gt;abs()</span></span>
<span id="cb64-15"><a href="#cb64-15" aria-hidden="true" tabindex="-1"></a>            loss <span class="op">=</span> loss <span class="op">+</span> l2_lambda <span class="op">*</span> l2_norm</span>
<span id="cb64-16"><a href="#cb64-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb64-17"><a href="#cb64-17" aria-hidden="true" tabindex="-1"></a>            optimizer.zero_grad()</span>
<span id="cb64-18"><a href="#cb64-18" aria-hidden="true" tabindex="-1"></a>            loss.backward()</span>
<span id="cb64-19"><a href="#cb64-19" aria-hidden="true" tabindex="-1"></a>            optimizer.step()</span>
<span id="cb64-20"><a href="#cb64-20" aria-hidden="true" tabindex="-1"></a>            </span>
<span id="cb64-21"><a href="#cb64-21" aria-hidden="true" tabindex="-1"></a>            loss_train <span class="op">+=</span> loss.item()</span>
<span id="cb64-22"><a href="#cb64-22" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> epoch <span class="op">==</span> <span class="dv">1</span> <span class="kw">or</span> epoch <span class="op">%</span> <span class="dv">10</span> <span class="op">==</span> <span class="dv">0</span>:</span>
<span id="cb64-23"><a href="#cb64-23" aria-hidden="true" tabindex="-1"></a>            <span class="bu">print</span>(<span class="st">'</span><span class="sc">{}</span><span class="st"> Epoch </span><span class="sc">{}</span><span class="st">, Training loss </span><span class="sc">{}</span><span class="st">'</span>.<span class="bu">format</span>(</span>
<span id="cb64-24"><a href="#cb64-24" aria-hidden="true" tabindex="-1"></a>                datetime.datetime.now(), epoch,</span>
<span id="cb64-25"><a href="#cb64-25" aria-hidden="true" tabindex="-1"></a>                loss_train <span class="op">/</span> <span class="bu">len</span>(train_loader)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="드랍아웃-입력-하나에-너무-의존하지-않기" class="level3">
<h3 class="anchored" data-anchor-id="드랍아웃-입력-하나에-너무-의존하지-않기">2. 드랍아웃: 입력 하나에 너무 의존하지 않기</h3>
<ul>
<li>매 훈련마다 무작위의 뉴런을 사용하기 때문에 신경망이 입력 샘플을 암기하려는 과적합을 방지</li>
<li>컨볼루션 전용 값인 nn.Dropout2d 나 nn.Dropout3d를 사용하여 해당 입력값의 채널을 0으로 만든다</li>
</ul>
<div class="cell" data-execution_count="31">
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NetDropout(nn.Module):</span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_chans1<span class="op">=</span><span class="dv">32</span>):</span>
<span id="cb65-3"><a href="#cb65-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb65-4"><a href="#cb65-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_chans1 <span class="op">=</span> n_chans1</span>
<span id="cb65-5"><a href="#cb65-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, n_chans1, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-6"><a href="#cb65-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1_dropout <span class="op">=</span> nn.Dropout2d(p<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb65-7"><a href="#cb65-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(n_chans1, n_chans1 <span class="op">//</span> <span class="dv">2</span>, kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb65-8"><a href="#cb65-8" aria-hidden="true" tabindex="-1"></a>                               padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb65-9"><a href="#cb65-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2_dropout <span class="op">=</span> nn.Dropout2d(p<span class="op">=</span><span class="fl">0.4</span>)</span>
<span id="cb65-10"><a href="#cb65-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> n_chans1 <span class="op">//</span> <span class="dv">2</span>, <span class="dv">32</span>)</span>
<span id="cb65-11"><a href="#cb65-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>)</span>
<span id="cb65-12"><a href="#cb65-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb65-13"><a href="#cb65-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb65-14"><a href="#cb65-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.tanh(<span class="va">self</span>.conv1(x)), <span class="dv">2</span>)</span>
<span id="cb65-15"><a href="#cb65-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv1_dropout(out)</span>
<span id="cb65-16"><a href="#cb65-16" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.tanh(<span class="va">self</span>.conv2(out)), <span class="dv">2</span>)</span>
<span id="cb65-17"><a href="#cb65-17" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv2_dropout(out)</span>
<span id="cb65-18"><a href="#cb65-18" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="va">self</span>.n_chans1 <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb65-19"><a href="#cb65-19" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.tanh(<span class="va">self</span>.fc1(out))</span>
<span id="cb65-20"><a href="#cb65-20" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc2(out)</span>
<span id="cb65-21"><a href="#cb65-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="배치-정규화-활성-함수-억제하기" class="level3">
<h3 class="anchored" data-anchor-id="배치-정규화-활성-함수-억제하기">3. 배치 정규화: 활성 함수 억제하기</h3>
<ul>
<li>배치 정규화의 핵심은 입력 범위를 신경망의 활성 함수로 바꿔서 미니 배치가 원하는 분포를 가지도록 한다</li>
<li>nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d 모듈로 배치 정규화</li>
<li>목적은 입력 범위를 조정하는 것이므로 자연스럽게 선형 변환 뒤(컨볼루션)에 위치하게 된다</li>
</ul>
<div class="cell" data-execution_count="32">
<div class="sourceCode cell-code" id="cb66"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NetBatchNorm(nn.Module):</span>
<span id="cb66-2"><a href="#cb66-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_chans1<span class="op">=</span><span class="dv">32</span>):</span>
<span id="cb66-3"><a href="#cb66-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb66-4"><a href="#cb66-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_chans1 <span class="op">=</span> n_chans1</span>
<span id="cb66-5"><a href="#cb66-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, n_chans1, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-6"><a href="#cb66-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1_batchnorm <span class="op">=</span> nn.BatchNorm2d(num_features<span class="op">=</span>n_chans1)</span>
<span id="cb66-7"><a href="#cb66-7" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(n_chans1, n_chans1 <span class="op">//</span> <span class="dv">2</span>, kernel_size<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb66-8"><a href="#cb66-8" aria-hidden="true" tabindex="-1"></a>                               padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb66-9"><a href="#cb66-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2_batchnorm <span class="op">=</span> nn.BatchNorm2d(num_features<span class="op">=</span>n_chans1 <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb66-10"><a href="#cb66-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> n_chans1 <span class="op">//</span> <span class="dv">2</span>, <span class="dv">32</span>)</span>
<span id="cb66-11"><a href="#cb66-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>)</span>
<span id="cb66-12"><a href="#cb66-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb66-13"><a href="#cb66-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb66-14"><a href="#cb66-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv1_batchnorm(<span class="va">self</span>.conv1(x))</span>
<span id="cb66-15"><a href="#cb66-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.tanh(out), <span class="dv">2</span>)</span>
<span id="cb66-16"><a href="#cb66-16" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv2_batchnorm(<span class="va">self</span>.conv2(out))</span>
<span id="cb66-17"><a href="#cb66-17" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.tanh(out), <span class="dv">2</span>)</span>
<span id="cb66-18"><a href="#cb66-18" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="va">self</span>.n_chans1 <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb66-19"><a href="#cb66-19" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.tanh(<span class="va">self</span>.fc1(out))</span>
<span id="cb66-20"><a href="#cb66-20" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc2(out)</span>
<span id="cb66-21"><a href="#cb66-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
</section>
<section id="구조를-더-깊게" class="level2">
<h2 class="anchored" data-anchor-id="구조를-더-깊게">구조를 더 깊게</h2>
<section id="스킵-커넥션" class="level3">
<h3 class="anchored" data-anchor-id="스킵-커넥션">1. 스킵 커넥션</h3>
<p>forward 함수의 첫 번째 계층의 출력을 세번째 계층의 입력에 추가해준다</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NetRes(nn.Module):</span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_chans1<span class="op">=</span><span class="dv">32</span>):</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_chans1 <span class="op">=</span> n_chans1</span>
<span id="cb67-5"><a href="#cb67-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, n_chans1, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb67-6"><a href="#cb67-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv2 <span class="op">=</span> nn.Conv2d(n_chans1, n_chans1 <span class="op">//</span> <span class="dv">2</span>, kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb67-7"><a href="#cb67-7" aria-hidden="true" tabindex="-1"></a>                               padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb67-8"><a href="#cb67-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv3 <span class="op">=</span> nn.Conv2d(n_chans1 <span class="op">//</span> <span class="dv">2</span>, n_chans1 <span class="op">//</span> <span class="dv">2</span>,</span>
<span id="cb67-9"><a href="#cb67-9" aria-hidden="true" tabindex="-1"></a>                               kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb67-10"><a href="#cb67-10" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> n_chans1 <span class="op">//</span> <span class="dv">2</span>, <span class="dv">32</span>)</span>
<span id="cb67-11"><a href="#cb67-11" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>)</span>
<span id="cb67-12"><a href="#cb67-12" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb67-13"><a href="#cb67-13" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb67-14"><a href="#cb67-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.relu(<span class="va">self</span>.conv1(x)), <span class="dv">2</span>)</span>
<span id="cb67-15"><a href="#cb67-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.relu(<span class="va">self</span>.conv2(out)), <span class="dv">2</span>)</span>
<span id="cb67-16"><a href="#cb67-16" aria-hidden="true" tabindex="-1"></a>        out1 <span class="op">=</span> out</span>
<span id="cb67-17"><a href="#cb67-17" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.relu(<span class="va">self</span>.conv3(out)) <span class="op">+</span> out1, <span class="dv">2</span>) <span class="co"># 이 부분</span></span>
<span id="cb67-18"><a href="#cb67-18" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">4</span> <span class="op">*</span> <span class="dv">4</span> <span class="op">*</span> <span class="va">self</span>.n_chans1 <span class="op">//</span> <span class="dv">2</span>)</span>
<span id="cb67-19"><a href="#cb67-19" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(out))</span>
<span id="cb67-20"><a href="#cb67-20" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc2(out)</span>
<span id="cb67-21"><a href="#cb67-21" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="파이토치로-매우-깊은-모델-만들기" class="level3">
<h3 class="anchored" data-anchor-id="파이토치로-매우-깊은-모델-만들기">2. 파이토치로 매우 깊은 모델 만들기</h3>
<div class="cell">
<div class="sourceCode cell-code" id="annotated-cell-46"><pre class="sourceCode python code-annotation-code code-with-copy code-annotated"><code class="sourceCode python"><span id="annotated-cell-46-1"><a href="#annotated-cell-46-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> ResBlock(nn.Module):</span>
<span id="annotated-cell-46-2"><a href="#annotated-cell-46-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_chans):</span>
<span id="annotated-cell-46-3"><a href="#annotated-cell-46-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>(ResBlock, <span class="va">self</span>).<span class="fu">__init__</span>()</span>
<span id="annotated-cell-46-4"><a href="#annotated-cell-46-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv <span class="op">=</span> nn.Conv2d(n_chans, n_chans, kernel_size<span class="op">=</span><span class="dv">3</span>,</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-46" data-target-annotation="1" onclick="event.preventDefault();">1</a><span id="annotated-cell-46-5" class="code-annotation-target"><a href="#annotated-cell-46-5" aria-hidden="true" tabindex="-1"></a>                              padding<span class="op">=</span><span class="dv">1</span>, bias<span class="op">=</span><span class="va">False</span>)</span>
<span id="annotated-cell-46-6"><a href="#annotated-cell-46-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.batch_norm <span class="op">=</span> nn.BatchNorm2d(num_features<span class="op">=</span>n_chans)</span>
<span id="annotated-cell-46-7"><a href="#annotated-cell-46-7" aria-hidden="true" tabindex="-1"></a>        torch.nn.init.kaiming_normal_(<span class="va">self</span>.conv.weight,</span>
<a class="code-annotation-anchor" data-target-cell="annotated-cell-46" data-target-annotation="2" onclick="event.preventDefault();">2</a><span id="annotated-cell-46-8" class="code-annotation-target"><a href="#annotated-cell-46-8" aria-hidden="true" tabindex="-1"></a>                                      nonlinearity<span class="op">=</span><span class="st">'relu'</span>)</span>
<span id="annotated-cell-46-9"><a href="#annotated-cell-46-9" aria-hidden="true" tabindex="-1"></a>        torch.nn.init.constant_(<span class="va">self</span>.batch_norm.weight, <span class="fl">0.5</span>)</span>
<span id="annotated-cell-46-10"><a href="#annotated-cell-46-10" aria-hidden="true" tabindex="-1"></a>        torch.nn.init.zeros_(<span class="va">self</span>.batch_norm.bias)</span>
<span id="annotated-cell-46-11"><a href="#annotated-cell-46-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="annotated-cell-46-12"><a href="#annotated-cell-46-12" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="annotated-cell-46-13"><a href="#annotated-cell-46-13" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.conv(x)</span>
<span id="annotated-cell-46-14"><a href="#annotated-cell-46-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.batch_norm(out)</span>
<span id="annotated-cell-46-15"><a href="#annotated-cell-46-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.relu(out)</span>
<span id="annotated-cell-46-16"><a href="#annotated-cell-46-16" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out <span class="op">+</span> x</span><div class="code-annotation-gutter-bg"></div><div class="code-annotation-gutter"></div></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-annotation">
<dl class="code-annotation-container-grid">
<dt data-target-cell="annotated-cell-46" data-target-annotation="1">1</dt>
<dd>
<span data-code-lines="5" data-code-cell="annotated-cell-46" data-code-annotation="1">BatchNorm 계층은 편향값의 효과를 상쇄하므로, 관례상 이를 생략한다</span>
</dd>
<dt data-target-cell="annotated-cell-46" data-target-annotation="2">2</dt>
<dd>
<span data-code-lines="8" data-code-cell="annotated-cell-46" data-code-annotation="2">커스텀 초기화. .kaiming_normal_은 레즈넷 논문에서처럼 표준편차를 가지는 표준 랜덤 요소로 초기화해준다. 배치 정규화는 기본값으로 평균 0과 분산 0.5를 가지는 분포의 출력을 만들도록 초기화한다.</span>
</dd>
</dl>
</div>
</div>
<blockquote class="blockquote">
<p>블럭에 배치 정규화를 넣어 훈련 도중에 기울기 값이 없어지는 것을 방지. 이제 100개의 블럭을 가진 신경망을 만들어본다</p>
</blockquote>
<div class="cell" data-execution_count="36">
<div class="sourceCode cell-code" id="cb68"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> NetResDeep(nn.Module):</span>
<span id="cb68-2"><a href="#cb68-2" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> <span class="fu">__init__</span>(<span class="va">self</span>, n_chans1<span class="op">=</span><span class="dv">32</span>, n_blocks<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb68-3"><a href="#cb68-3" aria-hidden="true" tabindex="-1"></a>        <span class="bu">super</span>().<span class="fu">__init__</span>()</span>
<span id="cb68-4"><a href="#cb68-4" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.n_chans1 <span class="op">=</span> n_chans1</span>
<span id="cb68-5"><a href="#cb68-5" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.conv1 <span class="op">=</span> nn.Conv2d(<span class="dv">3</span>, n_chans1, kernel_size<span class="op">=</span><span class="dv">3</span>, padding<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb68-6"><a href="#cb68-6" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.resblocks <span class="op">=</span> nn.Sequential(</span>
<span id="cb68-7"><a href="#cb68-7" aria-hidden="true" tabindex="-1"></a>            <span class="op">*</span>(n_blocks <span class="op">*</span> [ResBlock(n_chans<span class="op">=</span>n_chans1)]))</span>
<span id="cb68-8"><a href="#cb68-8" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc1 <span class="op">=</span> nn.Linear(<span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> n_chans1, <span class="dv">32</span>)</span>
<span id="cb68-9"><a href="#cb68-9" aria-hidden="true" tabindex="-1"></a>        <span class="va">self</span>.fc2 <span class="op">=</span> nn.Linear(<span class="dv">32</span>, <span class="dv">2</span>)</span>
<span id="cb68-10"><a href="#cb68-10" aria-hidden="true" tabindex="-1"></a>        </span>
<span id="cb68-11"><a href="#cb68-11" aria-hidden="true" tabindex="-1"></a>    <span class="kw">def</span> forward(<span class="va">self</span>, x):</span>
<span id="cb68-12"><a href="#cb68-12" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(torch.relu(<span class="va">self</span>.conv1(x)), <span class="dv">2</span>)</span>
<span id="cb68-13"><a href="#cb68-13" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.resblocks(out)</span>
<span id="cb68-14"><a href="#cb68-14" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> F.max_pool2d(out, <span class="dv">2</span>)</span>
<span id="cb68-15"><a href="#cb68-15" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> out.view(<span class="op">-</span><span class="dv">1</span>, <span class="dv">8</span> <span class="op">*</span> <span class="dv">8</span> <span class="op">*</span> <span class="va">self</span>.n_chans1)</span>
<span id="cb68-16"><a href="#cb68-16" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> torch.relu(<span class="va">self</span>.fc1(out))</span>
<span id="cb68-17"><a href="#cb68-17" aria-hidden="true" tabindex="-1"></a>        out <span class="op">=</span> <span class="va">self</span>.fc2(out)</span>
<span id="cb68-18"><a href="#cb68-18" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> out</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<ul>
<li>꼼꼼하게 초기화를 하고 훈련시키기 위해 3e - 3을 사용</li>
</ul>


</section>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>